# 训练 dataset_1593.xyz 的完整指南

## 📋 准备工作

### 1. 确认环境
- ✅ Python 3.9.6
- ✅ PyTorch 2.8.0 (支持 MPS)
- ✅ nequip 0.11.1
- ✅ nequip-allegro 0.6.3
- ✅ 数据文件: `data/dataset_1593.xyz` (309042 行，包含 1593 个水分子结构)

### 2. 数据信息
- **原子类型**: H (氢), O (氧)
- **每个结构**: 约 192 个原子
- **数据格式**: extxyz
- **字段映射**:
  - `TotEnergy` → `total_energy`
  - `force` → `forces`

## 🚀 训练步骤

### 步骤 1: 进入项目目录
```bash
cd /Users/lijunchen/coding
```

### 步骤 2: 进入 allegro 目录
```bash
cd allegro
```

### 步骤 3: 开始训练
```bash
nequip-train configs/dataset_1593_mps.yaml
```

## 📊 训练配置说明

### 数据集划分
- **训练集**: 1200 个结构
- **验证集**: 200 个结构
- **测试集**: 193 个结构

### 模型参数
- **cutoff_radius**: 5.0 Å
- **num_scalar_features**: 64
- **num_layers**: 2
- **l_max**: 1
- **学习率**: 0.001

### 训练设置
- **最大轮数**: 100 epochs
- **加速器**: MPS (Apple Silicon)
- **batch_size**: 4 (训练), 8 (验证)

## 📁 输出文件

训练完成后，会在 `experiments/outputs/` 目录下生成：
- `best.ckpt`: 最佳模型（验证损失最小）
- `last.ckpt`: 最后一轮的模型
- 训练日志和指标

## 🔍 监控训练

训练过程中会显示：
- 训练损失
- 验证损失
- 能量和力的 MAE (平均绝对误差)
- 进度条

## ⚠️ 注意事项

1. **MPS 加速**: 使用 Apple M4 的 GPU 加速，训练速度会比 CPU 快很多
2. **内存使用**: 如果遇到内存不足，可以减小 `batch_size`
3. **训练时间**: 根据数据量和模型大小，可能需要几小时到一天
4. **中断恢复**: 如果训练中断，可以修改配置继续训练（需要设置 checkpoint 路径）

## 🐛 常见问题

### 问题 1: 找不到数据文件
**解决**: 确保从 `allegro` 目录运行命令，配置文件中的路径是相对于 `allegro` 目录的

### 问题 2: MPS 不可用
**解决**: 检查 PyTorch 版本和 MPS 支持：
```python
import torch
print(torch.backends.mps.is_available())
```

### 问题 3: 内存不足
**解决**: 减小 `batch_size` 或 `num_workers`

## 📝 下一步

训练完成后，你可以：
1. 使用训练好的模型进行推理
2. 评估模型在测试集上的性能
3. 调整超参数重新训练
4. 导出模型用于 LAMMPS 等 MD 软件

