# yamllint disable rule:line-length
# MPS训练配置文件 - dataset_1593.xyz (水分子数据集) - Apple Silicon 优化
run: [train, test]

cutoff_radius: 5.0
model_type_names: [H, O]
chemical_species: ${model_type_names}

data:
  _target_: nequip.data.datamodule.ASEDataModule
  seed: 123
  split_dataset:
    - file_path: /Users/lijunchen/coding/allegro/data/dataset_1593.xyz
      train: 1200
      val: 200
      test: 193
  transforms:
    - _target_: nequip.data.transforms.ChemicalSpeciesToAtomTypeMapper
      chemical_symbols: ${model_type_names}
    - _target_: nequip.data.transforms.NeighborListTransform
      r_max: ${cutoff_radius}
  ase_args:
    format: extxyz
  key_mapping:
    TotEnergy: total_energy  # 将 TotEnergy 映射到 nequip 的 total_energy 字段
    force: forces  # 将 force (单数) 映射到 nequip 的 forces (复数) 字段
  train_dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 4  # MPS训练：使用较小的batch size
    num_workers: 2  # MPS训练：减少CPU workers
    pin_memory: false  # MPS不需要pin_memory
  val_dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: 8  # 验证时可以用稍大的batch size
    num_workers: 2
    pin_memory: false
  test_dataloader: ${data.val_dataloader}
  stats_manager:
    _target_: nequip.data.CommonDataStatisticsManager
    type_names: ${model_type_names}

trainer:
  _target_: lightning.Trainer
  max_epochs: 100
  log_every_n_steps: 10
  accelerator: cpu  # 暂时使用 CPU (MPS 有 float64 兼容性问题)
  devices: 1  # 使用1个设备
  enable_progress_bar: true  # 显示进度条
  callbacks:
    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      dirpath: ${hydra:runtime.output_dir}
      save_last: true
      save_top_k: 1  # 保存最佳模型（验证损失最小的）
      monitor: val0_epoch/weighted_sum  # 监控验证加权损失（NequIP使用的指标名称）
      mode: min  # 保存验证损失最小的模型
      filename: best  # 最佳模型文件名（将保存为 best.ckpt）

# NOTE: interpolation parameters for Allegro model
# MPS训练优化参数
num_scalar_features: 64  # 可以使用较大的特征数

training_module:
  _target_: nequip.train.EMALightningModule
  loss:
    _target_: nequip.train.EnergyForceLoss
    per_atom_energy: true
    coeffs:
      total_energy: 1.0
      forces: 1.0
  val_metrics:
    _target_: nequip.train.EnergyForceMetrics
    coeffs:
      per_atom_energy_mae: 1.0
      forces_mae: 1.0
  test_metrics: ${training_module.val_metrics}
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.001
  # ^ IMPORTANT: Allegro models do better with learning rates around 1e-3

  model:
    _target_: allegro.model.AllegroModel

    # MPS训练：torch.compile 在 MPS 上可能不稳定，暂时不使用
    # compile_mode: compile  # 如果需要可以尝试启用

    # === basic model params ===
    seed: 456
    model_dtype: float32
    type_names: ${model_type_names}
    r_max: ${cutoff_radius}

    # === two-body scalar embedding ===
    radial_chemical_embed:
      _target_: allegro.nn.TwoBodyBesselScalarEmbed
      num_bessels: 8
      bessel_trainable: false
      polynomial_cutoff_p: 6

    radial_chemical_embed_dim: ${num_scalar_features}

    # scalar embedding MLP
    scalar_embed_mlp_hidden_layers_depth: 1
    scalar_embed_mlp_hidden_layers_width: ${num_scalar_features}
    scalar_embed_mlp_nonlinearity: silu

    # === core hyperparameters ===
    l_max: 1  # MPS训练：l_max=1 更快且稳定
    num_layers: 2
    num_scalar_features: ${num_scalar_features}
    num_tensor_features: 32  # 可以使用较大的张量特征数

    # == allegro MLPs ==
    allegro_mlp_hidden_layers_depth: 1
    allegro_mlp_hidden_layers_width: ${num_scalar_features}
    allegro_mlp_nonlinearity: silu

    # === advanced hyperparameters ===
    parity: true
    tp_path_channel_coupling: true

    # == readout MLP ==
    readout_mlp_hidden_layers_depth: 1
    readout_mlp_hidden_layers_width: ${num_scalar_features}
    readout_mlp_nonlinearity: silu

    # === misc hyperparameters ===
    avg_num_neighbors: ${training_data_stats:num_neighbors_mean}
    per_type_energy_shifts: ${training_data_stats:per_atom_energy_mean}
    per_type_energy_scales: ${training_data_stats:forces_rms}
    per_type_energy_scales_trainable: false
    per_type_energy_shifts_trainable: false

global_options:
  allow_tf32: false

